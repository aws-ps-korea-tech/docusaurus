---
title: Quickstart Hail (English)
sidebar_position: 4
---

#  {#bkmrk-%C2%A0}

Deploy an [EMR cluster on AWS](https://aws.amazon.com/emr/){rel="nofollow"}, with Spark, [Hail](https://hail.is/index.html){rel="nofollow"}, [Zeppelin](https://zeppelin.apache.org/){rel="nofollow"} and [Ensembl VEP](https://ensembl.org/info/docs/tools/vep/index.html){rel="nofollow"} using CloudFormation service.

This tool requires the following programs to be previously installed in your computer:\

- Amazon\'s `Command Line Interface (CLI)` utility
- Git

To install the required software open a terminal and execute the following:

For Mac:

``` {#bkmrk-%23-installs-homebrew-}
# Installs homebrew
ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"

# Installs AWS CLI
brew install awscli
```

For Debian / Ubuntu (apt-get):

``` {#bkmrk-curl-%22https%3A%2F%2Fawscli}
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

sudo apt-get install -y git
```

For Fedora (dnf/yum):

``` {#bkmrk-curl-%22https%3A%2F%2Fawscli-1}
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

sudo dnf install git # or sudo yum install git
```

For Amazon Linux 2023:

``` {#bkmrk-sudo-dnf-install-git}
sudo dnf install git
```

# CloudFormation stack preparation {#bkmrk-%EC%8A%A4%ED%83%9D-%EC%8B%A4%ED%96%89}

1\. Prepare the AWS credentials and apply them in the terminal. \

``` {#bkmrk-export-aws_default_r}
export AWS_DEFAULT_REGION="{AWS_REGION}"
export AWS_ACCESS_KEY_ID="{ACCESS_KEY}"
export AWS_SECRET_ACCESS_KEY="{SECRET_ACCESS_KEY}"
export AWS_SESSION_TOKEN="{SESSION_TOKEN}"
```

2\. Create an S3 bucket in the region where you want to launch this CloudFormation stack.

``` {#bkmrk-aws-s3-mb-s3%3A%2F%2F%7B%EB%B2%84%ED%82%B7%EC%9D%B4%EB%A6%84}
aws s3 mb s3://{bucket name} --region {region}
```

Download and unzip the content from this repository, then place the downloaded content into the S3 bucket you created earlier.

``` {#bkmrk-export-aws_bucket%3D%7B%EB%B2%84}
export AWS_BUCKET={bucket name}
git clone https://github.com/hmkim/quickstart-hail.git
cd quickstart-hail
aws s3 sync . s3://$AWS_BUCKET/quickstart-hail/ --exclude ".git/*"
```

3\. Connect to the Amazon S3 console and check the bucket and directory.

[\![\](/img/omics-on-aws/uaCimage.png)](/img/omics-on-aws/uaCimage.png){target="_blank" rel="noopener"}

\

# Run the CloudFormation stack {#bkmrk-%EC%8A%A4%ED%83%9D-%EC%8B%A4%ED%96%89-1}

1\. Go to the [CloudFormation](https://us-east-1.console.aws.amazon.com/cloudformation/home?region=us-east-1) console.\

\![\](/img/omics-on-aws/wADscreenshot-2024-06-21-at-10-26-55-pm.png)

2\. Creates a new stack. At this time, select **`With new resources (standard)`**.\

\![\](/img/omics-on-aws/M7Hscreenshot-2024-06-21-at-10-27-22-pm.png)

3\. Go to the Amazon S3 console, select `hail-launcher.template.yaml` in the template directory you uploaded earlier, and click **`Copy URL`**. The path is as follows:

**{bucket name} \> quickstart-hail \> templates \> hail-launcher.template.yaml**

[\![\](/img/omics-on-aws/image.png)](/img/omics-on-aws/image.png){target="_blank" rel="noopener"}

When creating a CloudFormation stack, enter this URL and create the stack.

[\![\](/img/omics-on-aws/Whlimage.png)](/img/omics-on-aws/Whlimage.png){target="_blank" rel="noopener"}

4\. Proceed with entering information to create a stack.\

Type an name for the stack.

[\![\](/img/omics-on-aws/JI3image.png)](/img/omics-on-aws/JI3image.png){target="_blank" rel="noopener"}

Select a VPC. Select one subnet within the same VPC. For this exercise, select public.

\![\](/img/omics-on-aws/Yhguntitled-2.png)

Let\'s set it up to create additional buckets as needed.

Enter the name of the existing bucket where the `quickstart-hail` folder was uploaded, and check the region.

Here, the bucket name `awsimd-us-east-1` was used, and the `Hail S3 bucket name` and `Sagemaker home directory S3 bucket name` were suffixed with `-s3` and `-sm`, respectively. Modify the bucket names as appropriate.\

\![\](/img/omics-on-aws/kRNuntitled-3.png)

\![\](/img/omics-on-aws/Gn9untitled-4.png)

5\. Finally, press the **`Next`** button to create the stack.

\![\](/img/omics-on-aws/el0untitled-5.png)

\![\](/img/omics-on-aws/SZ9untitled-6.png)

6\. Check stack creation in CloudFormation.

\![\](/img/omics-on-aws/Y8muntitled-7.png)

If the following portfolio appears in the output along with the **`CREATE_COMPLETE`** message in the top stack, you can confirm that it was executed correctly.

\![\](/img/omics-on-aws/ejCuntitled-8.png)

# Create an AMI for Hail and VEP {#bkmrk-hail-%EB%B0%8F-vep%EB%A5%BC-%EC%9C%84%ED%95%9C-ami-%EC%83%9D}

## Pre-downloading VEP Data and Storing in Bucket {#bkmrk-vep-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%82%AC%EC%A0%84-%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C-%EB%B0%8F-%EB%B2%84%ED%82%B7}

For VEP, you can pre-download the data and store it in the bucket created or specified through the stack (using the `bucketHail` value from CloudFormation\'s Outputs).\

[\![\](/img/omics-on-aws/jY3image.png)](/img/omics-on-aws/jY3image.png){target="_blank" rel="noopener"}

\![\](/img/omics-on-aws/eELuntitled-10.png)

Download VEP data using the wget command:\

``` {#bkmrk-wget-ftp%3A%2F%2Fftp.ensem}
wget ftp://ftp.ensembl.org/pub/release-112/variation/vep/homo_sapiens_vep_112_GRCh37.tar.gz
```

Upload the downloaded file to your bucket: ([I emphasize that this is the value for the `BucketHail` key confirmed in CloudFormation Outputs]{style="color: rgb(224, 62, 45);"})\

``` {#bkmrk-aws-s3-cp-homo_sapie}
aws s3 cp homo_sapiens_vep_112_GRCh37.tar.gz s3://{defined Hail S3 bucket}/vep/cache/
```

## AMI Build  {#bkmrk-ami-%EB%B9%8C%EB%93%9C}

1\. Access the [CodeBuild console](https://us-east-1.console.aws.amazon.com/codesuite/codebuild/projects?region=us-east-1) and initiate the build process for each new AMI. Select Start build \> Start with overrides.

[\![\](/img/omics-on-aws/t6qimage.png)](/img/omics-on-aws/t6qimage.png){target="_blank" rel="noopener"}

[\![\](/img/omics-on-aws/zwjimage.png)](/img/omics-on-aws/zwjimage.png){target="_blank" rel="noopener"}

2\. In the Environment section, expand Additional configuration and input the required values.\

[\![\](/img/omics-on-aws/Nz5image.png)](/img/omics-on-aws/Nz5image.png){target="_blank" rel="noopener"}

[\![\](/img/omics-on-aws/6rnimage.png)](/img/omics-on-aws/6rnimage.png){target="_blank" rel="noopener"}

  HAIL_VERSION       0.2.105
  ------------------ ---------
  HTSLIB_VERSION     1.20
  SAMTOOLS_VERSION   1.20

\* For building with hail-vep option (includes VEP installation):\

  ---------------------------------------------------------------------------------------------------
  HAIL_VERSION                        0.2.105
  ----------------------------------- ---------------------------------------------------------------
  HTSLIB_VERSION                      1.20

  SAMTOOLS_VERSION                    1.20

  VEP_VERSION                         107

  **RODA_BUCKET**                     **value for the `BucketHail` key in CloudFormation Outputs\**
  ---------------------------------------------------------------------------------------------------

[\![\](/img/omics-on-aws/rYGimage.png)](/img/omics-on-aws/rYGimage.png){target="_blank" rel="noopener"}

3\. Check the build status in CodeBuild\

**Hail (without VEP):** The Hail image build completes in about 20 minutes.

[\![\](/img/omics-on-aws/9Wlimage.png)](/img/omics-on-aws/9Wlimage.png){target="_blank" rel="noopener"}

[\![\](/img/omics-on-aws/VdYimage.png)](/img/omics-on-aws/VdYimage.png){target="_blank" rel="noopener"}

**Hail (VEP)**: The VEP version build takes approximately 1 hour and 38 minutes to complete.\

\![\](/img/omics-on-aws/I3Cscreenshot-2024-06-24-at-9-31-00-am.png)

\![\](/img/omics-on-aws/KxIscreenshot-2024-06-24-at-9-31-12-am.png)

You can find the \*\*AMI results\*\* in either the AMI menu of [Amazon EC2 console](https://console.aws.amazon.com/ec2/) or CodeBuild logs.

[\![\](/img/omics-on-aws/IgJimage.png)](/img/omics-on-aws/IgJimage.png){target="_blank" rel="noopener"}

# **EMR Cluster Setup and Jupyter Environment Configuration** {#bkmrk-emr-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%8B%A4%ED%96%89-%EB%B0%8F-jupyte}

## EMR Cluster Setup {#bkmrk-emr-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%8B%A4%ED%96%89}

1\. In the CloudFormation service console\'s Outputs tab, click the portfolio.

[\![\](/img/omics-on-aws/9emimage.png)](/img/omics-on-aws/9emimage.png){target="_blank" rel="noopener"}

2\. In the portfolio of AWS Service Catalog, locate the relevant Product, click the Access tab, then select Grant access.\

[\![\](/img/omics-on-aws/qjKimage.png)](/img/omics-on-aws/qjKimage.png){target="_blank" rel="noopener"}

3\. Add permissions. Check the user that suits you and grant them access to Hail Products. Search for it, select it, and click Grant access.\

[\![\](/img/omics-on-aws/A2zimage.png)](/img/omics-on-aws/A2zimage.png){target="_blank" rel="noopener"}

[\![\](/img/omics-on-aws/0lWimage.png)](/img/omics-on-aws/0lWimage.png){target="_blank" rel="noopener"}

4\. After confirming access permissions, navigate to the Product in the Provisioning menu.\

[\![\](/img/omics-on-aws/UvRimage.png)](/img/omics-on-aws/UvRimage.png){target="_blank" rel="noopener"}

5\. With permissions granted, you should now see 2 Products listed.\

[\![\](/img/omics-on-aws/ZYiimage.png)](/img/omics-on-aws/ZYiimage.png){target="_blank" rel="noopener"}

6\. Select the Hail EMR Cluster product and click Launch product.\

\![\](/img/omics-on-aws/MLountitled-19.png)

7\. Enter the required launch information.\

Either enter a name manually or click Generate name.\

\![\](/img/omics-on-aws/ubMuntitled-20.png)

Specify the Hail AMI you created earlier. You can find the AMI ID in the EC2 service\'s AMIs section (as previously described).\

\![\](/img/omics-on-aws/jHsuntitled-21.png)

Input the Cluster name and Hail AMI ID. You can leave all other settings at their default values.\

\![\](/img/omics-on-aws/sEGuntitled-22.png)

8\. Click Launch product at the bottom of the page.\

\![\](/img/omics-on-aws/nz9screenshot-2024-07-08-at-11-47-56-am.png)

## SageMaker Notebook Setup {#bkmrk-sagemaker-notebook-%EC%8B%A4}

1\. Similarly, select Launch product in the Product menu.\

[\![\](/img/omics-on-aws/p2Eimage.png)](/img/omics-on-aws/p2Eimage.png){target="_blank" rel="noopener"}

2\. Provide a name for your Hail notebook instance. Keep all other settings at their defaults.\

\![\](/img/omics-on-aws/Ro2untitled-24.png)

3\. Click Launch product at the bottom of the page.\

\![\](/img/omics-on-aws/PcJscreenshot-2024-07-08-at-11-47-56-am.png)

*\*Note: You can monitor the product deployment progress through CloudFormation.\*

[\![\](/img/omics-on-aws/CrLimage.png)](/img/omics-on-aws/CrLimage.png){target="_blank" rel="noopener"}

## numpy reinstall {#bkmrk-%C2%A0-3}

The issue occurs when running as it is currently. **As of Mar 14, 2025**

Therefore, it is necessary to check the cluster created by Amazon EMR as shown below, connect to the Primary instance, delete and reinstall the numpy module.

[\![\](/img/omics-on-aws/image.png)](/img/omics-on-aws/image.png){target="_blank" rel="noopener"}

[\![\](/img/omics-on-aws/sxXimage.png)](/img/omics-on-aws/sxXimage.png){target="_blank" rel="noopener"}[\![\](/img/omics-on-aws/xd0image.png)](/img/omics-on-aws/xd0image.png){target="_blank" rel="noopener"}

[\![\](/img/omics-on-aws/opximage.png)](/img/omics-on-aws/opximage.png){target="_blank" rel="noopener"}

``` {#bkmrk-sudo-python3--m-pip-}
sudo python3 -m pip uninstall -y numpy

sudo python3 -m pip install  numpy -U
```

\

# GWAS Practice using Hail {#bkmrk-gwas-%EC%8B%A4%EC%8A%B5-%28hail%29}

1\. Launch your notebook. Find the URL in CloudFormation\'s Outputs tab. Clicking it will automatically connect you to your notebook instance in Amazon SageMaker.\

\![\](/img/omics-on-aws/8BOuntitled-26.png)

2\. Select Open JupyterLab to start the notebook interface.\

\![\](/img/omics-on-aws/XaHuntitled-27.png)

3\. We\'ll work with two notebooks in this practice session:\

- common-notebooks/plotting-tutorail.ipynb
- common-notebooks/GWAS-tutorial.ipynb

\![\](/img/omics-on-aws/G4vscreenshot-2024-06-24-at-3-26-55-pm.png)

Locate your previously created EMR cluster and update the Cluster Name in the second cell.

You can execute notebook cells in sequence by placing your cursor in the cell where you want to begin.

\![\](/img/omics-on-aws/S5uuntitled-28.png)

When the tutorial code runs successfully, you should see results similar to these:

\![\](/img/omics-on-aws/Eevscreenshot-2024-07-08-at-12-21-50-pm.png)

\![\](/img/omics-on-aws/QUfuntitled-29.png)

\![\](/img/omics-on-aws/mCzscreenshot-2024-07-08-at-12-22-18-pm.png)

# Additional Information {#bkmrk-%EA%B8%B0%ED%83%80}

## VEP configuration {#bkmrk-vep-configuration}

In the S3 bucket, select the json file object and click Copy S3 URI.\

\![\](/img/omics-on-aws/untitled-30.png)

Ex: vep-configuration-GRCh37.json\

``` {#bkmrk-%7B-%22command%22%3A-%5B-%22%2Fopt}
{
        "command": [
                "/opt/ensembl-vep/vep",
                "--format", "vcf",
                "--dir_plugins", "/opt/vep/plugins",
                "--dir_cache", "/opt/vep/cache",
                "--json",
                "--everything",
                "--allele_number",
                "--no_stats",
                "--cache", "--offline",
                "--minimal",
                "--assembly", "GRCh37",
                "--plugin", "LoF,human_ancestor_fa:/opt/vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/opt/vep/loftee_data/phylocsf_gerp.sql,gerp_file:/opt/vep/loftee_data/GERP_scores.final.sorted.txt.gz",
                "-o", "STDOUT"
        ],
        "env": {
                "PERL5LIB": "/opt/vep"
        },
    "vep_json_schema": "Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac_allele:String,exac_afr_allele:String,exac_afr_maf:Float64,exac_amr_allele:String,exac_amr_maf:Float64,exac_eas_allele:String,exac_eas_maf:Float64,exac_fin_allele:String,exac_fin_maf:Float64,exac_maf:Float64,exac_nfe_allele:String,exac_nfe_maf:Float64,exac_oth_allele:String,exac_oth_maf:Float64,exac_sas_allele:String,exac_sas_maf:Float64,id:String,minor_allele:String,minor_allele_freq:Float64,phenotype_or_disease:Int32,pubmed:Array[Int32],sas_allele:String,sas_maf:Float64,somatic:Int32,start:Int32,strand:Int32}],context:String,end:Int32,id:String,input:String,intergenic_consequences:Array[Struct{allele_num:Int32,consequence_terms:Array[String],impact:String,minimised:Int32,variant_allele:String}],most_severe_consequence:String,motif_feature_consequences:Array[Struct{allele_num:Int32,consequence_terms:Array[String],high_inf_pos:String,impact:String,minimised:Int32,motif_feature_id:String,motif_name:String,motif_pos:Int32,motif_score_change:Float64,strand:Int32,variant_allele:String}],regulatory_feature_consequences:Array[Struct{allele_num:Int32,biotype:String,consequence_terms:Array[String],impact:String,minimised:Int32,regulatory_feature_id:String,variant_allele:String}],seq_region_name:String,start:Int32,strand:Int32,transcript_consequences:Array[Struct{allele_num:Int32,amino_acids:String,appris:String,biotype:String,canonical:Int32,ccds:String,cdna_start:Int32,cdna_end:Int32,cds_end:Int32,cds_start:Int32,codons:String,consequence_terms:Array[String],distance:Int32,domains:Array[Struct{db:String,name:String}],exon:String,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,tsl:Int32,uniparc:String,variant_allele:String}],variant_class:String}"
}
```

You can modify and implement the following content in the **[vep-tutorial](https://github.com/hmkim/quickstart-hail/blob/main/sagemaker/common-notebooks/vep-tutorial.ipynb)** code using the S3 object URI you copied above.

\![\](/img/omics-on-aws/screenshot-2024-07-11-at-11-07-00-am.png)

## VEP Plugin Installation {#bkmrk-vep-plugin-installat}

If you need to modify VEP plugin installations (additions, etc.), you\'ll need to rebuild the AMI. The VEP installation code is in **[vep_install.sh](https://github.com/hmkim/quickstart-hail/blob/main/packer-files/scripts/vep_install.sh)**. Modify this script and rebuild the AMI as needed.

For customizing Hail, VEP tool installation, and AMI building, refer to these resources:

##  {#bkmrk-vep-%ED%94%8C%EB%9F%AC%EA%B7%B8%EC%9D%B8-%EC%84%A4%EC%B9%98}

- [Hail AMI Creation via AWS CodeBuild](https://github.com/hmkim/quickstart-hail/blob/main/docs/hail-ami.md)
- [vep-install.md](https://github.com/hmkim/quickstart-hail/blob/main/docs/vep-install.md)
- [Building a Custom Hail AMI](https://github.com/hmkim/quickstart-hail/blob/main/docs/ami-creation.md)

## Dynamically Expanding EMR Cluster EBS (HDFS) Volume  {#bkmrk-emr-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-ebs-%28hdfs%29-}

When working with large datasets, you may find the initially configured cluster volume capacity insufficient. You can dynamically expand the EBS volume by following the guidance in this blog post:\

[[<https://aws.amazon.com/ko/blogs/big-data/dynamically-scale-up-storage-on-amazon-emr-clusters/>]{lang="EN-US" style="font-family: 'Malgun Gothic',sans-serif; color: #4472c4; mso-ansi-language: EN-US;"}]{.underline}

## FAQ {#bkmrk-faq .MsoNormal}

### Codebuild {#bkmrk-codebuild}

CLIENT_ERROR: error while downloading key ami/packer-files.zip, error: RequestError: send request failed caused by: Get \"https://{bucket name}.s3.amazonaws.com/ami/packer-files.zip\": dial tcp 3.5.30.46:443: i/o timeout for primary source\
